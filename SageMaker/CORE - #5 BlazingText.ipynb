{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE #4 Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ingestion of data in S3 from the CORE API stored data as JSONs with up to 100 search results stored in each file. \n",
    "Per [BlazingText Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext.html), the algorithm requires each line of the input file should contain a single sentence of space separated tokens. Raw data will need to be processed to accomodate the training format. \n",
    "* In # 3, text was extracted from the JSON results and stored in S3. This code picks up from there, prepares the text for modeling, and stores to S3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_bucket_name = 'core0823'\n",
    "stg_bucket = 'core0823-stg'\n",
    "fnl_bucket = 'core0823-fnl'\n",
    "psent_key='BT_STG/prepd_sentences.txt'\n",
    "\n",
    "train_data_path = 's3://{}/{}'.format(stg_bucket,psent_key)\n",
    "model_path = 's3://{}/{}'.format(fnl_bucket,'blztxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BlazingText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "region_name = boto3.Session().region_name\n",
    "container = sagemaker.amazon.amazon_estimator.get_image_uri(region_name, 'blazingtext','latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "bt_model = sagemaker.estimator.Estimator(container,\n",
    "                                        role,\n",
    "                                        train_instance_count=2,\n",
    "                                        train_instance_type='ml.m4.xlarge',\n",
    "                                        train_volume_size=5,\n",
    "                                        train_max_run=360000,\n",
    "                                        input_mode='File',\n",
    "                                        output_path=model_path,\n",
    "                                        sagemaker_session = sess)\n",
    "\n",
    "bt_model.set_hyperparameters(mode='batch_skipgram',\n",
    "                            epochs=5,\n",
    "                            min_count=5,\n",
    "                            sampling_threshold=0.0001,\n",
    "                            learning_rate=0.05,\n",
    "                            window_size=5,\n",
    "                            vector_dim=100,\n",
    "                            negative_samples=5,\n",
    "                            batch_size=11,\n",
    "                            evaluation=True,\n",
    "\n",
    "                             subwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# need to check that content_type='text/plain' is correct because pickle dumps was used to write list to file\n",
    "bt_train_data = sagemaker.session.s3_input(train_data_path, distribution='FullyReplicated',\n",
    "                                          content_type='text/plain',s3_data_type='S3Prefix')\n",
    "\n",
    "bt_data_channels = {'train' : bt_train_data }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-21 23:02:48 Starting - Starting the training job...\n",
      "2020-09-21 23:02:51 Starting - Launching requested ML instances......\n",
      "2020-09-21 23:04:07 Starting - Preparing the instances for training.........\n",
      "2020-09-21 23:05:44 Downloading - Downloading input data\n",
      "2020-09-21 23:05:44 Training - Downloading the training image...\n",
      "2020-09-21 23:06:04 Training - Training image download completed. Training in progress.\u001b[35mArguments: train\u001b[0m\n",
      "\u001b[35mFound 10.2.83.8 for host algo-1\u001b[0m\n",
      "\u001b[35mFound 10.2.103.143 for host algo-2\u001b[0m\n",
      "\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34mFound 10.2.83.8 for host algo-1\u001b[0m\n",
      "\u001b[34mFound 10.2.103.143 for host algo-2\u001b[0m\n",
      "\u001b[35m[09/21/2020 23:06:16 WARNING 139719394350912] Loggers have already been setup.\u001b[0m\n",
      "\u001b[35m[09/21/2020 23:06:16 WARNING 139719394350912] Loggers have already been setup.\u001b[0m\n",
      "\u001b[35m[09/21/2020 23:06:16 INFO 139719394350912] nvidia-smi took: 0.0251860618591 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[35m[09/21/2020 23:06:16 INFO 139719394350912] Running distributed CPU BlazingText training using batch_skipgram on 2 hosts.\u001b[0m\n",
      "\u001b[35m[09/21/2020 23:06:16 INFO 139719394350912] Number of hosts: 2, master IP address: 10.2.83.8, host IP address: 10.2.103.143.\u001b[0m\n",
      "\u001b[34m[09/21/2020 23:06:17 WARNING 139793345468224] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[09/21/2020 23:06:17 WARNING 139793345468224] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[09/21/2020 23:06:17 INFO 139793345468224] nvidia-smi took: 0.0251779556274 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[09/21/2020 23:06:17 INFO 139793345468224] Running distributed CPU BlazingText training using batch_skipgram on 2 hosts.\u001b[0m\n",
      "\u001b[34m[09/21/2020 23:06:17 INFO 139793345468224] Number of hosts: 2, master IP address: 10.2.83.8, host IP address: 10.2.83.8.\u001b[0m\n",
      "\u001b[34m[09/21/2020 23:06:17 INFO 139793345468224] HTTP server started....\u001b[0m\n",
      "\u001b[34m[09/21/2020 23:06:17 INFO 139793345468224] Processing /opt/ml/input/data/train/prepd_sentences.txt . File size: 399 MB\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-2,10.2.103.143' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mprocessor name: algo-2, number of processors: 2, rank: 1\u001b[0m\n",
      "\u001b[34mprocessor name: algo-1, number of processors: 2, rank: 0\u001b[0m\n",
      "\u001b[34mRead 10M words\u001b[0m\n",
      "\u001b[34mRead 20M words\u001b[0m\n",
      "\u001b[34mRead 30M words\u001b[0m\n",
      "\u001b[34mRead 40M words\u001b[0m\n",
      "\u001b[34mRead 50M words\u001b[0m\n",
      "\u001b[34mRead 60M words\u001b[0m\n",
      "\u001b[34mRead 63M words\u001b[0m\n",
      "\u001b[34mNumber of words:  270901\u001b[0m\n",
      "\u001b[34mAlpha: 0.0490  Progress: 2.04%  Million Words/sec: 1.58\u001b[0m\n",
      "\u001b[34mAlpha: 0.0464  Progress: 7.05%  Million Words/sec: 1.58\u001b[0m\n",
      "\u001b[34mAlpha: 0.0440  Progress: 12.07%  Million Words/sec: 1.51\u001b[0m\n",
      "\u001b[34mAlpha: 0.0415  Progress: 17.12%  Million Words/sec: 1.44\u001b[0m\n",
      "\u001b[34mAlpha: 0.0390  Progress: 22.15%  Million Words/sec: 1.46\u001b[0m\n",
      "\u001b[34mAlpha: 0.0365  Progress: 27.16%  Million Words/sec: 1.46\u001b[0m\n",
      "\u001b[34mAlpha: 0.0340  Progress: 32.21%  Million Words/sec: 1.43\u001b[0m\n",
      "\u001b[34mAlpha: 0.0315  Progress: 37.25%  Million Words/sec: 1.44\u001b[0m\n",
      "\u001b[34mAlpha: 0.0290  Progress: 42.30%  Million Words/sec: 1.44\u001b[0m\n",
      "\u001b[34mAlpha: 0.0265  Progress: 47.32%  Million Words/sec: 1.42\u001b[0m\n",
      "\u001b[34mAlpha: 0.0239  Progress: 52.34%  Million Words/sec: 1.43\u001b[0m\n",
      "\u001b[34mAlpha: 0.0214  Progress: 57.36%  Million Words/sec: 1.43\u001b[0m\n",
      "\u001b[34mAlpha: 0.0189  Progress: 62.39%  Million Words/sec: 1.42\u001b[0m\n",
      "\u001b[34mAlpha: 0.0163  Progress: 67.43%  Million Words/sec: 1.43\u001b[0m\n",
      "\u001b[34mAlpha: 0.0137  Progress: 72.48%  Million Words/sec: 1.43\u001b[0m\n",
      "\u001b[34mAlpha: 0.0111  Progress: 77.53%  Million Words/sec: 1.44\u001b[0m\n",
      "\u001b[34mAlpha: 0.0086  Progress: 82.57%  Million Words/sec: 1.42\u001b[0m\n",
      "\u001b[34mAlpha: 0.0061  Progress: 87.60%  Million Words/sec: 1.43\u001b[0m\n",
      "\u001b[34mAlpha: 0.0036  Progress: 92.62%  Million Words/sec: 1.43\u001b[0m\n",
      "\u001b[34mAlpha: 0.0010  Progress: 97.64%  Million Words/sec: 1.42\u001b[0m\n",
      "\u001b[34mAlpha: 0.0000  Progress: 100.00%  Million Words/sec: 1.41\n",
      "\u001b[0m\n",
      "\u001b[34mTraining finished!\u001b[0m\n",
      "\u001b[34mAverage throughput in Million words/sec: 1.41\u001b[0m\n",
      "\u001b[34mTotal training time in seconds: 224.78\u001b[0m\n",
      "\u001b[34mEvaluating word embeddings....\u001b[0m\n",
      "\u001b[34mVectors read from: /opt/ml/model/vectors.txt \u001b[0m\n",
      "\u001b[34m{\n",
      "    \"EN-WS-353-ALL.txt\": {\n",
      "        \"not_found\": 14, \n",
      "        \"spearmans_rho\": 0.5197115909055849, \n",
      "        \"total_pairs\": 353\n",
      "    }, \n",
      "    \"EN-WS-353-REL.txt\": {\n",
      "        \"not_found\": 6, \n",
      "        \"spearmans_rho\": 0.48993297401313907, \n",
      "        \"total_pairs\": 252\n",
      "    }, \n",
      "    \"EN-WS-353-SIM.txt\": {\n",
      "        \"not_found\": 9, \n",
      "        \"spearmans_rho\": 0.5376053008153878, \n",
      "        \"total_pairs\": 203\n",
      "    }, \n",
      "    \"mean_rho\": 0.5157499552447039\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[09/21/2020 23:10:50 INFO 139793345468224] #mean_rho: 0.5157499552447039\u001b[0m\n",
      "\u001b[35m[09/21/2020 23:12:10 INFO 139719394350912] Master host is not alive. Training might have finished. Shutting down.... Check the logs for algo-1 machine.\u001b[0m\n",
      "\n",
      "2020-09-21 23:12:12 Uploading - Uploading generated training model\n",
      "2020-09-21 23:13:40 Completed - Training job completed\n",
      "Training seconds: 998\n",
      "Billable seconds: 998\n"
     ]
    }
   ],
   "source": [
    "bt_model.fit(inputs=bt_data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
