{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE #3 Text Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ingestion of data in S3 from the CORE API stored data as JSONs with up to 100 search results stored in each file. \n",
    "Per [BlazingText Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext.html), the algorithm requires each line of the input file should contain a single sentence of space separated tokens. Raw data will need to be processed to accomodate the training format. \n",
    "* This notebook extracts text from the JSON and stores it in S3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_bucket_name = 'core0823'\n",
    "stg_bucket = 'core0823-stg'\n",
    "stg_catalog_bucket = stg_bucket + '/Catalog'\n",
    "stg_bt_bucket = stg_bucket + '/BT_STG'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = [i['Key'] for i in s3_client.list_objects(Bucket=core_bucket_name)['Contents']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_file_location(f_bucket, f_file):\n",
    "    \"\"\"\n",
    "    Simply returns a formatted string with the S3 file location\n",
    "    \"\"\"\n",
    "    data_location = 's3://{}/{}'.format(f_bucket,f_file)\n",
    "    return data_location\n",
    "\n",
    "def json_file_to_dict(f_bucket, f_json_file):\n",
    "    \"\"\"\n",
    "    Intakes bucket and json file.\n",
    "    Returns dictionary.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json_s3_obj = s3_client.get_object( Bucket= f_bucket, Key = f_json_file )\n",
    "        tmp_str_json = json_s3_obj['Body'].read().decode('utf-8')\n",
    "        fnl_json = ast.literal_eval(tmp_str_json)\n",
    "        return fnl_json\n",
    "    except:\n",
    "        pass \n",
    "        print('Fail importing json file/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_text_parse(f_bucket, f_file_name):\n",
    "    \"\"\"\n",
    "    Intakes a bucket and file name. \n",
    "    Parses CORE API JSON.     \n",
    "    Returns list of lists, where each entry is a sentence.\n",
    "    \"\"\"\n",
    "    results_list = []\n",
    "    tmp_file = json_file_to_dict(f_bucket, f_file_name)\n",
    "    if tmp_file is not None and tmp_file['data'] is not None:\n",
    "        for item in tmp_file['data']:\n",
    "            if item['_source']['description'] is not None:\n",
    "                tmp_parse_list = tokenize.sent_tokenize(item['_source']['description'])\n",
    "                results_list.extend(tmp_parse_list)\n",
    "\n",
    "            if item['_source']['fullText'] is not None:\n",
    "                tmp_parse_list = tokenize.sent_tokenize(item['_source']['fullText'])\n",
    "                results_list.extend(tmp_parse_list)\n",
    "            \n",
    "    return results_list\n",
    "\n",
    "\n",
    "def json_extract_text(f_bucket, f_file_list):\n",
    "    \"\"\"\n",
    "    Intakes a bucket and list of JSON files from CORE API. \n",
    "    Parses CORE API JSON. \n",
    "    This function iterates over a list of files, where json_text_parse is for a single file.\n",
    "    Returns list of lists, where each entry is a sentence.\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    print('JSON extract text starting at: {}'.format(t0))\n",
    "    results_list = []\n",
    "    for file in f_file_list:\n",
    "        tmp_results = json_text_parse(f_bucket, file)\n",
    "        results_list.extend(tmp_results)\n",
    "    \n",
    "    results_list = [sent for sent in results_list if len(sent) > 1]\n",
    "    t1 = time.time()\n",
    "    print('JSON extract text complete at: {}'.format(t1))\n",
    "    print('JSON extract text tool: {}'.format(t1-t0))\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = json_extract_text(core_bucket_name, json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "sentences_serialized = pickle.dumps(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.put_object(Body=sentences_serialized, Bucket='core0823-stg', Key='BT_STG/sentences.txt')"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
